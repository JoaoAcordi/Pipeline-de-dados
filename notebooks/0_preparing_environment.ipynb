{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90849ab1",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Databricks notebook source\n",
    "# MAGIC %md\n",
    "# MAGIC # 1. Preparando o Ambiente - Pipeline de Filmes\n",
    "# MAGIC \n",
    "# MAGIC **Objetivo:** Criar toda a infraestrutura necessária no Unity Catalog (Catálogo, Schemas, Volume) para o pipeline de dados de filmes.\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "# Cria um novo catálogo para o projeto de filmes, caso ele não exista\n",
    "spark.sql(\"CREATE CATALOG IF NOT EXISTS movies_catalog\")\n",
    "spark.sql(\"USE CATALOG movies_catalog\")\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "# Cria os schemas para as camadas Bronze, Silver e Gold\n",
    "spark.sql(\"CREATE SCHEMA IF NOT EXISTS bronze\")\n",
    "spark.sql(\"CREATE SCHEMA IF NOT EXISTS silver\")\n",
    "spark.sql(\"CREATE SCHEMA IF NOT EXISTS gold\")\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "# MAGIC %md\n",
    "# MAGIC ### Criar o Volume e Fazer Upload dos Dados\n",
    "# MAGIC \n",
    "# MAGIC 1.  **Execute a célula abaixo** para criar o Volume.\n",
    "# MAGIC 2.  **Vá para a interface do Databricks:** `Data > movies_catalog > bronze > landing_zone_movies`.\n",
    "# MAGIC 3.  **Clique em \"Upload to this volume\"** e envie o arquivo `top_100_movies_full_best_effort.csv`.\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "# Cria o volume que servirá como Landing Zone para os arquivos brutos\n",
    "# O volume será criado dentro do catálogo e schema atualmente em uso (movies_catalog.bronze)\n",
    "spark.sql(\"CREATE VOLUME IF NOT EXISTS landing_zone_movies\")\n",
    "print(\"Ambiente preparado com sucesso!\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
