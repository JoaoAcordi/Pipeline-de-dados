{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97bbf723",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Databricks notebook source\n",
    "# MAGIC %md\n",
    "# MAGIC # 2. Camada Bronze - Ingestão dos Dados de Filmes\n",
    "# MAGIC \n",
    "# MAGIC **Objetivo:** Ler o arquivo CSV bruto da Landing Zone e salvá-lo como uma tabela Delta na camada Bronze.\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "from pyspark.sql.functions import current_timestamp, input_file_name\n",
    "\n",
    "# Define o catálogo e o schema a serem usados\n",
    "spark.sql(\"USE CATALOG movies_catalog\")\n",
    "spark.sql(\"USE SCHEMA bronze\")\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "# Caminho para o arquivo no volume\n",
    "landing_path = \"/Volumes/movies_catalog/bronze/landing_zone_movies/top_100_movies_full_best_effort.csv\"\n",
    "bronze_table_name = \"movies_raw\"\n",
    "\n",
    "# Leitura do arquivo CSV bruto\n",
    "df_raw = spark.read.format(\"csv\") \\\n",
    "                   .option(\"header\", \"true\") \\\n",
    "                   .option(\"inferSchema\", \"true\") \\\n",
    "                   .load(landing_path)\n",
    "\n",
    "# Adiciona metadados de controle\n",
    "df_bronze = df_raw.withColumn(\"data_ingestao\", current_timestamp()) \\\n",
    "                  .withColumn(\"arquivo_origem\", input_file_name())\n",
    "\n",
    "# Salva como uma tabela Delta na camada Bronze\n",
    "df_bronze.write.mode(\"overwrite\") \\\n",
    "         .option(\"overwriteSchema\", \"true\") \\\n",
    "         .saveAsTable(bronze_table_name)\n",
    "\n",
    "print(f\"Tabela '{bronze_table_name}' criada com sucesso na camada Bronze.\")\n",
    "display(spark.table(bronze_table_name))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
