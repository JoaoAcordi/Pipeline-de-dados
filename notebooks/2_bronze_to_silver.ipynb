{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da6731d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notebook: 2_bronze_to_silver\n",
    "bronze_prefix = \"dbfs:/mnt/datalake/bronze\"\n",
    "silver_prefix = \"dbfs:/mnt/datalake/silver\"\n",
    "\n",
    "movies = spark.read.format(\"delta\").load(f\"{bronze_prefix}/movies_top100\")\n",
    "ratings = spark.read.format(\"delta\").load(f\"{bronze_prefix}/movies_ratings\")\n",
    "revenue = spark.read.format(\"delta\").load(f\"{bronze_prefix}/movies_revenue\")\n",
    "casts = spark.read.format(\"delta\").load(f\"{bronze_prefix}/movies_casts\")\n",
    "meta = spark.read.format(\"delta\").load(f\"{bronze_prefix}/movies_meta\")\n",
    "\n",
    "from pyspark.sql.functions import col, trim\n",
    "movies = movies.withColumn(\"Year\", trim(col(\"Year\")).cast(\"int\"))\n",
    "ratings = ratings.withColumn(\"IMDb_Rating\", col(\"IMDb_Rating\").cast(\"double\"))\n",
    "\n",
    "silver = (movies.join(ratings, [\"Title\"], \"left\")\n",
    "    .join(revenue, [\"Title\"], \"left\")\n",
    "    .join(casts, [\"Title\"], \"left\")\n",
    "    .join(meta, [\"Title\"], \"left\")\n",
    "    .dropDuplicates([\"Title\"]))\n",
    "silver.write.format(\"delta\").mode(\"overwrite\").option(\"overwriteSchema\",\"true\").partitionBy(\"Year\").save(f\"{silver_prefix}/top100_combined\")\n",
    "print(\"silver written\")\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
